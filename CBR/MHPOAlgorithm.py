import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import math
import random

class MHPOAlgorithm:
    """
    æ”¹è¿›çš„çŒç‰©-æ•é£Ÿè€…ä¼˜åŒ–ç®—æ³•ï¼ˆModified Hunter-Prey Optimizationï¼‰
    ç”¨äºCBRæ¨¡å‹ä¸­ç‰¹å¾å‚æ•°çš„æƒé‡åˆ†é…ä¼˜åŒ–
    """
    
    def __init__(self, population_size=30, max_iterations=500, dim=7):
        self.population_size = population_size
        self.max_iterations = max_iterations
        self.dim = dim  # æƒé‡ç»´åº¦ï¼ˆç‰¹å¾æ•°é‡ï¼‰
        self.lb = 0.0   # æƒé‡ä¸‹ç•Œ
        self.ub = 1.0   # æƒé‡ä¸Šç•Œ
        
        # ç®—æ³•å‚æ•°
        self.C = 2 * random.random()  # éšæœºå‚æ•°
        self.Z = 2 * random.random()  # éšæœºå‚æ•°
        
    def levy_flight(self, beta=1.5):
        """Levyé£è¡Œåˆ†å¸ƒ"""
        sigma = (math.gamma(1 + beta) * math.sin(math.pi * beta / 2) / 
                (math.gamma((1 + beta) / 2) * beta * (2 ** ((beta - 1) / 2)))) ** (1 / beta)
        
        u = np.random.normal(0, sigma)
        v = np.random.normal(0, 1)
        step = u / (abs(v) ** (1 / beta))
        return step
    
    def initialize_population(self):
        """åˆå§‹åŒ–ç§ç¾¤"""
        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))
        
        # ç¡®ä¿æƒé‡å’Œä¸º1çš„çº¦æŸ
        for i in range(self.population_size):
            population[i] = population[i] / np.sum(population[i])
        
        return population
    
    def fitness_function(self, weights, X_train, y_train, X_test, y_test, k=4):
        """
        CBRæ¨¡å‹çš„é€‚åº”åº¦å‡½æ•° - è®¡ç®—MSE
        ä½¿ç”¨åŠ æƒæ¬§å‡ é‡Œå¾—è·ç¦»è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—
        """
        try:
            # ç¡®ä¿æƒé‡å’Œä¸º1
            weights = weights / np.sum(weights)
            
            predictions = []
            
            for test_sample in X_test:
                # è®¡ç®—ä¸æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„åŠ æƒè·ç¦»
                distances = []
                for train_sample in X_train:
                    # åŠ æƒæ¬§å‡ é‡Œå¾—è·ç¦»
                    weighted_diff = weights * (test_sample - train_sample) ** 2
                    distance = np.sqrt(np.sum(weighted_diff))
                    distances.append(distance)
                
                # æ‰¾åˆ°kä¸ªæœ€è¿‘é‚»
                distances = np.array(distances)
                k_nearest_indices = np.argsort(distances)[:k]
                
                # ä½¿ç”¨kä¸ªæœ€è¿‘é‚»çš„å¹³å‡å€¼ä½œä¸ºé¢„æµ‹
                k_nearest_targets = y_train[k_nearest_indices]
                prediction = np.mean(k_nearest_targets)
                predictions.append(prediction)
            
            # è®¡ç®—MSE
            mse = mean_squared_error(y_test, predictions)
            return mse
            
        except Exception as e:
            return 1e6  # è¿”å›ä¸€ä¸ªå¾ˆå¤§çš„å€¼è¡¨ç¤ºé”™è¯¯
    
    def update_position(self, position, best_position, iteration):
        """æ›´æ–°ä½ç½®çš„æ”¹è¿›æœºåˆ¶"""
        new_position = position.copy()
        
        # è‡ªé€‚åº”å˜å¼‚å› å­
        f = 0.4 * np.exp(np.exp(1 - self.max_iterations / (self.max_iterations + 1 - iteration)))
        
        # éšæœºæ•°qå†³å®šæœç´¢ç­–ç•¥
        q = random.random()
        
        for j in range(self.dim):
            r1, r2, r3 = random.random(), random.random(), random.random()
            
            if q >= 0.5:
                # ç­–ç•¥1ï¼šåŸºäºæœ€ä¼˜ä½ç½®çš„æœç´¢
                new_position[j] = position[j] + 0.5 * (
                    (2 * self.C * self.Z * best_position[j] - position[j]) +
                    (2 * (1 - self.C) * self.Z * np.mean(best_position) - position[j])
                )
            elif 0.25 <= q < 0.5:
                # ç­–ç•¥2ï¼šåŸºäºå½“å‰æœ€ä¼˜è§£çš„æœç´¢
                new_position[j] = (best_position[j] - np.mean(best_position)) - r2 * (
                    self.lb + r3 * (self.ub - self.lb))
            else:
                # ç­–ç•¥3ï¼šLevyé£è¡Œéšæœºæœç´¢
                levy_step = self.levy_flight()
                rand_pos = random.uniform(self.lb, self.ub)
                new_position[j] = rand_pos - levy_step * abs(rand_pos - 2 * r1 * position[j])
        
        # è¾¹ç•Œå¤„ç†
        new_position = np.clip(new_position, self.lb, self.ub)
        
        # å·®åˆ†è¿›åŒ–å˜å¼‚
        if random.random() < 0.3:  # 30%æ¦‚ç‡è¿›è¡Œå˜å¼‚
            r1, r2, r3 = np.random.choice(len(new_position), 3, replace=False)
            new_position = new_position + f * (new_position - new_position)
        
        # ç¡®ä¿æƒé‡å’Œä¸º1
        new_position = new_position / np.sum(new_position)
        
        return new_position
    
    def optimize(self, X_train, y_train, X_test, y_test):
        """
        ä¸»ä¼˜åŒ–å¾ªç¯ - è‡ªåŠ¨è°ƒæ•´æƒé‡ä»¥æœ€å°åŒ–MSE
        è¿™æ˜¯æƒé‡è‡ªåŠ¨ä¼˜åŒ–çš„æ ¸å¿ƒéƒ¨åˆ†
        """
        # åˆå§‹åŒ–ç§ç¾¤ï¼ˆéšæœºæƒé‡ç»„åˆï¼‰
        population = self.initialize_population()
        fitness_values = np.zeros(self.population_size)
        
        # è®¡ç®—åˆå§‹é€‚åº”åº¦ï¼ˆæ¯ä¸ªæƒé‡ç»„åˆçš„MSEï¼‰
        print("ğŸ”„ è®¡ç®—åˆå§‹æƒé‡ç»„åˆçš„MSE...")
        for i in range(self.population_size):
            fitness_values[i] = self.fitness_function(population[i], X_train, y_train, X_test, y_test)
        
        # æ‰¾åˆ°æœ€ä¼˜ä¸ªä½“ï¼ˆMSEæœ€å°çš„æƒé‡ç»„åˆï¼‰
        best_idx = np.argmin(fitness_values)
        best_position = population[best_idx].copy()  # å½“å‰æœ€ä¼˜æƒé‡
        best_fitness = fitness_values[best_idx]      # å½“å‰æœ€å°MSE
        
        # è®°å½•æ”¶æ•›å†å²
        convergence_history = []
        weight_history = [best_position.copy()]  # è®°å½•æƒé‡å˜åŒ–
        
        print(f"ğŸ“Š åˆå§‹æœ€ä¼˜MSE: {best_fitness:.6f}")
        print(f"ğŸ“Š åˆå§‹æœ€ä¼˜æƒé‡: {best_position}")
        
        # ğŸš€ ä¸»ä¼˜åŒ–å¾ªç¯ - è‡ªåŠ¨æƒé‡è°ƒæ•´è¿‡ç¨‹
        for iteration in range(self.max_iterations):
            improved_count = 0  # è®°å½•æœ¬è½®æ”¹è¿›æ¬¡æ•°
            
            for i in range(self.population_size):
                # ğŸ¯ å…³é”®æ­¥éª¤1: ç”Ÿæˆæ–°çš„æƒé‡ç»„åˆ
                new_position = self.update_position(population[i], best_position, iteration)
                
                # ğŸ¯ å…³é”®æ­¥éª¤2: è®¡ç®—æ–°æƒé‡ç»„åˆä¸‹çš„MSE
                new_fitness = self.fitness_function(new_position, X_train, y_train, X_test, y_test)
                
                # ğŸ¯ å…³é”®æ­¥éª¤3: å¦‚æœæ–°MSEæ›´å°ï¼Œå°±æ¥å—æ–°æƒé‡
                if new_fitness < fitness_values[i]:
                    population[i] = new_position
                    fitness_values[i] = new_fitness
                    improved_count += 1
                    
                    # ğŸ¯ å…³é”®æ­¥éª¤4: æ›´æ–°å…¨å±€æœ€ä¼˜æƒé‡ï¼ˆå¦‚æœæ‰¾åˆ°æ›´å°çš„MSEï¼‰
                    if new_fitness < best_fitness:
                        old_mse = best_fitness
                        best_position = new_position.copy()
                        best_fitness = new_fitness
                        weight_history.append(best_position.copy())
                        
                        print(f"ğŸ‰ å‘ç°æ›´ä¼˜æƒé‡! è¿­ä»£{iteration+1}: MSE {old_mse:.6f} â†’ {best_fitness:.6f}")
            
            # è®°å½•å½“å‰æœ€ä¼˜é€‚åº”åº¦
            convergence_history.append(best_fitness)
            
            # æ‰“å°è¿›åº¦
            if (iteration + 1) % 50 == 0:
                print(f"ğŸ“ˆ è¿­ä»£ {iteration + 1}/{self.max_iterations}: MSE = {best_fitness:.6f}, æœ¬è½®æ”¹è¿›{improved_count}æ¬¡")
        
        print(f"\nâœ… æƒé‡ä¼˜åŒ–å®Œæˆ!")
        print(f"ğŸ¯ æœ€ç»ˆæœ€ä¼˜MSE: {best_fitness:.6f}")
        print(f"ğŸ¯ æƒé‡è°ƒæ•´æ¬¡æ•°: {len(weight_history)}")
        
        return best_position, best_fitness, convergence_history

def load_and_prepare_data(file_path='normalized_case_vectors.csv'):
    """åŠ è½½å’Œå‡†å¤‡æ•°æ®"""
    try:
        # è¯»å–å½’ä¸€åŒ–æ•°æ®
        df = pd.read_csv(file_path)
        print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
        print(f"åˆ—å: {df.columns.tolist()}")
        
        # å‡è®¾æœ€åä¸€åˆ—æ˜¯ç›®æ ‡å˜é‡ï¼ˆå¦‚è®ºæ–‡ä¸­çš„æ€»é¢ç§¯ï¼‰
        # å¦‚æœæ²¡æœ‰ç›®æ ‡åˆ—ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªåˆæˆçš„ç›®æ ‡
        if 'target' in df.columns:
            X = df.drop('target', axis=1).values
            y = df['target'].values
        else:
            # ä½¿ç”¨å‰n-1åˆ—ä½œä¸ºç‰¹å¾ï¼Œæœ€åä¸€åˆ—ä½œä¸ºç›®æ ‡
            X = df.iloc[:, :-1].values
            y = df.iloc[:, -1].values
        
        print(f"ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
        print(f"ç›®æ ‡å‘é‡å½¢çŠ¶: {y.shape}")
        
        return X, y
        
    except Exception as e:
        print(f"æ•°æ®åŠ è½½é”™è¯¯: {e}")
        # ç”Ÿæˆç¤ºä¾‹æ•°æ®ç”¨äºæµ‹è¯•
        print("ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæµ‹è¯•...")
        np.random.seed(42)
        X = np.random.rand(102, 7)  # 102ä¸ªæ ·æœ¬ï¼Œ7ä¸ªç‰¹å¾
        y = np.random.rand(102) * 1000  # ç›®æ ‡å€¼
        return X, y

def main():
    """ä¸»å‡½æ•°"""
    print("=== MHPOç®—æ³•ç”¨äºCBRæƒé‡ä¼˜åŒ– ===\n")
    
    # åŠ è½½æ•°æ®
    X, y = load_and_prepare_data('normalized_case_vectors.csv')
    
    # åˆ’åˆ†è®­ç»ƒå’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"è®­ç»ƒé›†å¤§å°: {X_train.shape[0]}")
    print(f"æµ‹è¯•é›†å¤§å°: {X_test.shape[0]}")
    print(f"ç‰¹å¾ç»´åº¦: {X_train.shape[1]}\n")
    
    # åˆ›å»ºMHPOç®—æ³•å®ä¾‹
    mhpo = MHPOAlgorithm(
        population_size=30,
        max_iterations=500,
        dim=X_train.shape[1]
    )
    
    print("å¼€å§‹ä¼˜åŒ–...")
    
    # è¿è¡Œä¼˜åŒ–
    best_weights, best_mse, convergence_history = mhpo.optimize(
        X_train, y_train, X_test, y_test
    )
    
    print(f"\n=== ä¼˜åŒ–ç»“æœ ===")
    print(f"æœ€ä¼˜MSE: {best_mse:.6f}")
    print(f"æœ€ä¼˜æƒé‡:")
    for i, weight in enumerate(best_weights):
        print(f"  ç‰¹å¾ {i+1}: {weight:.4f}")
    print(f"æƒé‡å’Œ: {np.sum(best_weights):.6f}")
    
    # ç»˜åˆ¶æ”¶æ•›æ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(convergence_history)
    plt.title('MHPOç®—æ³•æ”¶æ•›æ›²çº¿')
    plt.xlabel('è¿­ä»£æ¬¡æ•°')
    plt.ylabel('æœ€ä¼˜é€‚åº”åº¦ (MSE)')
    plt.grid(True)
    plt.show()
    
    # åˆ†ææƒé‡é‡è¦æ€§
    print(f"\n=== ç‰¹å¾é‡è¦æ€§åˆ†æ ===")
    feature_importance = [(i+1, weight) for i, weight in enumerate(best_weights)]
    feature_importance.sort(key=lambda x: x[1], reverse=True)
    
    for rank, (feature_idx, weight) in enumerate(feature_importance, 1):
        print(f"æ’å {rank}: ç‰¹å¾ {feature_idx} (æƒé‡: {weight:.4f})")
    
    return best_weights, best_mse, convergence_history

if __name__ == "__main__":
    best_weights, best_mse, convergence_history = main()